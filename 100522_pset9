Note: I did not look at the answer key while completing this assignment.

import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets, linear_model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

x = [3,4,5,6,7,8,9,11,12,14,15,16,17]
y = [1.4,1.5,2.2,2.4,3.1,3.2,3.2,3.9,4.1,4.7,4.5,5.2,5.0]

colors = np.random.rand(N)

plt.scatter(x, y, alpha=0.5)
plt.show()

# 1. Plot age vs wing length:

x = np.array([3,4,5,6,7,8,9,11,12,14,15,16,17]).reshape((-1,1))
y = np.array([1.4,1.5,2.2,2.4,3.1,3.2,3.2,3.9,4.1,4.7,4.5,5.2,5.0])
x2 = np.array([3,4,5,6,7,8,9,11,12,14,15,16,17])

plt.scatter(x, y, alpha=0.5)
plt.show()


# 2. Calculate and plot the regression line

model = LinearRegression().fit(x, y)
r_sq = model.score(x, y)
print(f"R sq is: {r_sq}")
print(f"slope is: {model.coef_}")

predictedy = model.predict(x)

plt.scatter(x, y, alpha=0.5)
plt.plot(x, predictedy, color="blue", linewidth=3)
plt.show()

# 3. Can you reject b=0?
Yes, you can reject because there is a clear trend with a positive slope of .265 and the r2 is .96. 

# 4. Calculate and plot the confidence intervals on the slope of the regression line
import numpy as np, statsmodels.api as sm
import seaborn as sns

mod = sm.OLS(y,x)
res = mod.fit()
print model.conf_int(.05)

95% CI is [[0.30976618 0.35906242]]
sns.regplot(x,y, color = 'blue')

# 5. Calculate Pearson's R 
print(f"Pearson's r is {st.pearsonr(x2, y)}")

Pearson's r is (0.981520377681628, 3.0097431724570356e-09)


# 6. Add some noise to the regression and see how it changes.


x = np.array([3,4,5,6,7,8,9,11,12,14,15,16,17,15,13,15,12,0]).reshape((-1,1))
y = np.array([1.4,1.5,2.2,2.4,3.1,3.2,3.2,3.9,4.1,4.7,4.5,5.2,5.0,1.5,1.0,3,4,1])

predictedy = model.predict(x)

plt.scatter(x, y, alpha=0.5)
plt.plot(x, predictedy, color="blue", linewidth=3)
plt.show()

Still pretty good fit. If more outliers were added or other values changed, slope may change
and confidence interval would get bigger.
